#!/usr/bin/python

"""
    File name: github_pr_comment_search.py
    Author: Ray Yeung (raymyeun)
    Date created: 4/20/2013
    Date last modified: 2/24/2017
    Python Version: 2.7
    Prerequisite:
        1. Set up Github personal access token (https://github.com/settings/tokens).
           Make sure token has full control of repositories
        2. Save the Github toekn and export it as GITHUB_TOKEN environment variable
    Description:
        Input:
            Option 1: Github repro name (user and repo), pull request state that user is interested in. (Default = open)
            e.g. 'python github_pr_comment_search.py --user TetrationAnalytics --repo deploy-ansible --state open'

            Option 2: Repo PR list file that was previously generated by this script.
            e.g. 'python github_pr_comment_search.py -f TetrationAnalytics_deploy-ansible_open_pr.list'
        Implementation:
            1. (With input option 1) script will scan through the github repository for pull request via api, and save
               needed info into a file (${user}_${repo}_${pr_state}_pr.list). This step has taken pagination into
               consideration. (Github only allows 100 returns per api request max.)
            2. Open the file mentioned above, and scan through github comments for the PR,
               grab PMR and CR related info, merge with the input line, and write
               into a file (${user}_${repo}_${pr_state}_pr_comment.list)
        Output:
            A file that contains PRM and CR info in the PR comments.
            Delimiter is '|', and the fields are:
            Field Number    Field Name          Field Description
            1:              pr_number           Pull request ID for the repository
            2:              pr_url              Pull request html URL
            3:              gh_user             Github user where the repository belongs
            4:              gh_repo             Github repository name
            5:              pr_owner            Pull request owner user login
            6:              pr_created_at       Pull request created time
            7:              pr_updated_at       Pull request updated time
            8:              pr_title            Pull request title
            9:              pr_comment_url      Pull request comment URL
            10:              run_pmr_user        Run PMR user id
            12:             run_pmr_time        Run PMR time
            12:             bypass_pmr_user     Bypass PMR user id
            13:             bypass_pmr_time     Bypass PMR time
            14:             start_pmr_link      Start PMR link
            15:             start_pmr_time      Start PMR time
            16:             fail_pmr_link       Fail PMR link
            17:             fail_pmr_time       Fail PMR time
            18:             bypass_cr_user      Bypass CR user id
            19:             bypass_cr_time      Bypass CR time

    Caveats: Github api only allows 5000 request per hour as rate limit. If too many entries, need to break down the
             Repo PR list file and run job into batches.
"""

import requests
import json
import re
import os
import argparse


#requests.get("https://api.github.com/repos/TetrationAnalytics/deploy-ansible/pulls?state=open&page=1&per_page=100&access_token=xxx")
def get_github_api_ratelimit_remaining (github_token):
    """ Return github api's user rate limit remaining. For authenticated user, rate limit is 5000 per hour """
    url = "https://api.github.com/rate_limit?access_token=" + github_token
    r = requests.head(url)
    print "Githut API rate limit remaining = " + r.headers['X-RateLimit-Remaining']
    return r.headers['X-RateLimit-Remaining']


def get_gh_repo_pr (repo, user="TetrationAnalytics", state='open', per_page=100, access_token='', delimiter='|'):
    """Grab all PRs in repository with pagination traversing, and save needed fields into a file."""
    # sample URL:
    # https://api.github.com/repos/TetrationAnalytics/deploy-ansible/pulls?state=all&page=1&per_page=100&access_token=xx

    # Use 1st page returned header to know last page number
    url = "https://api.github.com/repos/" + user + '/' + repo + '/pulls?' + \
          "state=" + state + "&page=" + "1" + "&per_page=" + str(per_page) +\
          '&access_token=' + access_token

    filename = '_'.join([user, repo, state, "pr.list"])
    line_count = 0

    fh = open (filename, "w")
    r = requests.head(url)
    #print r.headers
    if 'Link' in r.headers:
        # print r.headers['Link']
        # print r.links['next']
        # print r.links['last']['url']
        # print type(r.links['last']['url'])
        last_page_num = re.search("&page=(\d+)", r.links['last']['url']).group(1)
    else:
        last_page_num = 1

    for page in range(1, int(last_page_num)+1):
        url = "https://api.github.com/repos/" + user + '/' + repo + '/pulls?' + \
              "state=" + state + "&page=" + str(page) + "&per_page=" + str(per_page) + \
              '&access_token=' + access_token
        #r = requests.get("https://api.github.com/repos/TetrationAnalytics/deploy-ansible/pulls?state=open&page=1&per_page=100&access_token=xxx")
        r = requests.get(url)
        if(r.ok):
            #print json.dumps(r.content, indent=4, separators=(',', ': '))
            pr_list = json.loads(r.text or r.content)
            #print type (pr_list)
            #print len(pr_list)
            for pr in pr_list:
                output = delimiter.join([str(pr['number']), pr['html_url'], user, repo,\
                                         pr['user']['login'], pr['created_at'], pr['updated_at'],\
                                         pr['title'], pr['comments_url'], '\n'])
                fh.write(output.encode('utf-8'))
                line_count += 1
        else:
            print "ERROR: Something gone wrong with PR request.get"
    fh.close ()
    return filename, line_count


def get_gh_pr_comment (url, delimiter='|'):
    #r = requests.get("https://api.github.com/repos/TetrationAnalytics/deploy-ansible/issues/3141/comments", headers=headers)
    r = requests.get(url)

    if(r.ok):
        # print json.dumps(r.content, indent=4, separators=(',', ': '))
        # if re.search("bypass pmr", json.dumps(r.content, indent=4, separators=(',', ': '))):
        #     print "found prm bypass"
        commentList = json.loads(r.text or r.content)
        # print "number of comments in pr comment url" + str(len(commentList))
        run_pmr_user, run_pmr_time, bypass_pmr_user, bypass_pmr_time,\
        start_pmr_link, start_pmr_time, fail_pmr_link, fail_pmr_time,\
        bypass_cr_user, bypass_cr_time = (u'',) * 10

        for comment in commentList:
            comment_body = comment['body']
            if re.search("please run pmr", comment_body):
                run_pmr_user = comment['user']['login']
                run_pmr_time = comment['created_at']
            elif re.search("bypass pmr", comment_body):
                bypass_pmr_user = comment['user']['login']
                bypass_pmr_time = comment['created_at']
            elif re.search("PMR job started", comment_body):
                pattern = "MR job started, please see: "
                start_pmr_link = comment_body[re.search(pattern, comment_body).end():].strip()
                start_pmr_time = comment['created_at']
            elif re.search("PMR build failed", comment_body):
                pattern = "PMR build failed. "
                fail_pmr_link = comment_body[re.search(pattern, comment_body).end():].strip()
                fail_pmr_time = comment['created_at']
            elif re.search("bypass commit_regress", comment_body):
                bypass_cr_user = comment['user']['login']
                bypass_cr_time = comment['created_at']
            else:
                pass
        result_line = delimiter.join([run_pmr_user, run_pmr_time, bypass_pmr_user, bypass_pmr_time, \
                                start_pmr_link, start_pmr_time, fail_pmr_link, fail_pmr_time, \
                                bypass_cr_user, bypass_cr_time])
        return result_line


def get_gh_repo_pr_comment (filename, per_page=100, access_token='', delimiter='|'):

    # For particular comments
    # Open new file to write
    # Open pr list file, read in each line, split fields and grab comment_url
    # In comment api, scan for pmr/cr info, grab specific fields, append to the pr list line.
    # Save to new file
    in_filename = filename
    k = in_filename.rfind(".")
    out_filename = in_filename[:k] + "_comment" + in_filename[k:]

    with open(in_filename) as in_file, open(out_filename, 'w') as out_file:
        for line in in_file:
            in_line = line.strip().decode('utf-8')
            comment_url = line.split(delimiter)[8]
            #print comment_url
            pr_comment_url = comment_url + "?per_page=" + str(per_page) + '&access_token=' + access_token
            append_line = get_gh_pr_comment(pr_comment_url, delimiter).decode('utf-8')
            out_line = in_line + append_line + '\n'
            out_file.write(out_line.encode("utf-8"))

    return out_filename

        #user_login of comment, created time of the bypass,


# MAIN
parser = argparse.ArgumentParser()
parser.add_argument('-u', '--user', dest="gh_user", action="store",
                    help="Github user name", default="TetrationAnalytics")
parser.add_argument('-r', '--repo', dest="gh_repo", default='', action="store",
                    help="Github repository name")
parser.add_argument('-s', '--state', dest="pr_state", default="open", action="store",
                    help="Github pull request state, open/closed/all")
parser.add_argument('-f', '--filename', dest="pr_filename", default='', action="store",
                    help="Filename of Github PR list file")
args = vars(parser.parse_args())

gh_token = os.environ['GITHUB_TOKEN']
# gh_user = "TetrationAnalytics"
# gh_repo = "deploy-ansible"
# pr_state = "open"  # pr state in open, closed, all
gh_items_per_page = 100 # Max api.github.com supports
(gh_user, gh_repo, pr_state, pr_filename) = (args['gh_user'],  args['gh_repo'], args['pr_state'], args['pr_filename'])

if (gh_repo == '' and pr_filename == ''):
    print "ERROR: Input needed for repo info, or PR list file name"
    exit()
elif (gh_repo != ''):
    pr_filename, pr_count = get_gh_repo_pr (user=gh_user, repo=gh_repo, state=pr_state,\
                                            per_page=gh_items_per_page, access_token=gh_token)
    print "Done getting PR list."
    print "PR list is at: " + pr_filename + " (" +str(pr_count) + ")"

# Take care to rate limit
pr_count = len(open(pr_filename).readlines(  ))

if pr_count > get_github_api_ratelimit_remaining(gh_token):
    print "ERROR: Github api rate limit remaining < Repo PR list entries. \nNeed to split PR list into small batches."
    exit()
else:
    print "Ok to proceed. Github api rate limit remaining > Repo PR list entries"

output_file = get_gh_repo_pr_comment (filename=pr_filename, per_page=gh_items_per_page, access_token=gh_token, delimiter='|')
print "Done getting pr COMMENT list"
print "Output file = " + output_file
